# Money Validator

![Alt text](https://github.com/cpinan/AndroidDevChallenge/blob/master/androidDevChallenge.png?raw=true "Placeholder")

# Tell us what your idea is. 


Analyzing money is a must in our society. People with vision problems are often unable to use bills in transaction due to the issues corroborating which is the value that have in hand, so to overcome this problem, we propose a way to analyze bills in the device, allowing the user to know which is the value of the bill. Processing the image and converting it into audio and morse code. In this way the people can participate again in the market, using android technologies to interact with other people. Training models to understand the bills, the origin of the bill, and their value will definitely improve the way the market works in our world. In detail, we are going to get first bills from our market, and train models in the device to understand how they work, to compare value, images, and more. Integrating this with the device, and in the future with a way to validate if the bill is really valid, preventing frauds in the market based on probabilities. 


# Tell us how you plan on bringing it to life. 


I have not started yet with this project, but I had this idea to help people. I'm working in training models and trying to understand several concepts, so here is a brief of my planning for this project:

First of all, I'm understanding how I can make it work. Getting several types of bills to be processed using MLKit or Tensorflow Lite.


From my point of view, I can use Google's help for how to improve the performance time, also I have in mind integrating it with Google Translate or Google Lens. So, it could be a Google feature to help a lot of people.


## Regarding my timeline, here is the plan:

### November 2019:
- Android project setup
- Research and Learning Machine Learning

### December 2019:
- Understand in detail how ML on device works.
- Start training models, and make test.

### January 2019:
- Create an alpha android code to use it locally
- Document the models, and results.

### February 2019:
- Start with the UX Flow in detail, because in the beginning it's going to be a mock ui
- Apply the design into the apk with the local test.

### March 2019:
- Have a stable android application, integrated with ML
- Testing phase with alpha users using play store

### April 2019:
- Continue with the testing step.
- Bug fixing and improvements.

# Tell us about you. 
 

Hi, I'm Carlos Pi√±an, an android developer in Peru. I enjoy learning new things, and sharing them with the community. I'm new in machine learning, so I'm doing my best learning from several courses. I'm an enthusiastic, and I find this as an opportunity to improve my knowledge and to help people.

# References

https://docs.google.com/document/d/1mJHMsr0v_hoSXy4fL3vcX86RDGPvjRs6emx-g3VH07U/edit
